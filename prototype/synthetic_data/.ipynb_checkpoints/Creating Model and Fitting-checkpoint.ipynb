{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The following function is used for reading data and create x and y\n",
    "* It would take'csv' or 'tsv' file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/wangyuening/Documents/Research/Neuralizer/prototype/synthetic_data/synthetic_data.tsv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "location = os.path.abspath('synthetic_data.tsv')\n",
    "df_try = pd.read_csv('%s'%location)\n",
    "print(location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename,X_var,Y_var):\n",
    "    location = os.path.abspath(filename)\n",
    "    df = pd.read_csv('%s'%location,sep='\\t')\n",
    "    X = np.array(df[X_var].values)\n",
    "    Y = np.array(df[Y_var].values)\n",
    "    return X,Y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'synthetic_data.tsv'\n",
    "X_var = ['A','B','C']\n",
    "Y_var =['y']\n",
    "X,Y = read_file(filename=filename,X_var=X_var,Y_var=Y_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9261, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9261, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(X,Y,test_fraction,random_state):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_fraction, random_state=random_state)\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = split_train_test(X,Y,0.20,42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4963 samples, validate on 2445 samples\n",
      "Epoch 1/150\n",
      "4963/4963 [==============================] - 1s 154us/step - loss: 0.7043 - coeff_determination: -0.0035 - val_loss: 0.5940 - val_coeff_determination: 0.1246\n",
      "Epoch 2/150\n",
      "4963/4963 [==============================] - 0s 94us/step - loss: 0.6031 - coeff_determination: 0.1602 - val_loss: 0.5672 - val_coeff_determination: 0.1753\n",
      "Epoch 3/150\n",
      "4963/4963 [==============================] - 0s 93us/step - loss: 0.5684 - coeff_determination: 0.2385 - val_loss: 0.5264 - val_coeff_determination: 0.2308\n",
      "Epoch 4/150\n",
      "4963/4963 [==============================] - 0s 96us/step - loss: 0.5108 - coeff_determination: 0.2837 - val_loss: 0.4576 - val_coeff_determination: 0.3434\n",
      "Epoch 5/150\n",
      "4963/4963 [==============================] - 0s 96us/step - loss: 0.4284 - coeff_determination: 0.3855 - val_loss: 0.3720 - val_coeff_determination: 0.4697\n",
      "Epoch 6/150\n",
      "4963/4963 [==============================] - 0s 95us/step - loss: 0.3413 - coeff_determination: 0.5249 - val_loss: 0.2974 - val_coeff_determination: 0.5608\n",
      "Epoch 7/150\n",
      "4963/4963 [==============================] - 0s 94us/step - loss: 0.2708 - coeff_determination: 0.6213 - val_loss: 0.2439 - val_coeff_determination: 0.6386\n",
      "Epoch 8/150\n",
      "4963/4963 [==============================] - 0s 96us/step - loss: 0.2273 - coeff_determination: 0.6752 - val_loss: 0.2153 - val_coeff_determination: 0.6752\n",
      "Epoch 9/150\n",
      "4963/4963 [==============================] - 1s 109us/step - loss: 0.2012 - coeff_determination: 0.6881 - val_loss: 0.1934 - val_coeff_determination: 0.7048\n",
      "Epoch 10/150\n",
      "4963/4963 [==============================] - 0s 101us/step - loss: 0.1746 - coeff_determination: 0.7334 - val_loss: 0.1623 - val_coeff_determination: 0.7500\n",
      "Epoch 11/150\n",
      "4963/4963 [==============================] - 0s 96us/step - loss: 0.1338 - coeff_determination: 0.8078 - val_loss: 0.1128 - val_coeff_determination: 0.8273\n",
      "Epoch 12/150\n",
      "4963/4963 [==============================] - 0s 97us/step - loss: 0.0877 - coeff_determination: 0.8694 - val_loss: 0.0713 - val_coeff_determination: 0.8909\n",
      "Epoch 13/150\n",
      "4963/4963 [==============================] - 0s 94us/step - loss: 0.0606 - coeff_determination: 0.9107 - val_loss: 0.0544 - val_coeff_determination: 0.9163\n",
      "Epoch 14/150\n",
      "4963/4963 [==============================] - 0s 95us/step - loss: 0.0515 - coeff_determination: 0.9261 - val_loss: 0.0502 - val_coeff_determination: 0.9230\n",
      "Epoch 15/150\n",
      "4963/4963 [==============================] - 0s 98us/step - loss: 0.0489 - coeff_determination: 0.9284 - val_loss: 0.0473 - val_coeff_determination: 0.9271\n",
      "Epoch 16/150\n",
      "4963/4963 [==============================] - 1s 112us/step - loss: 0.0473 - coeff_determination: 0.9304 - val_loss: 0.0462 - val_coeff_determination: 0.9284\n",
      "Epoch 17/150\n",
      "4963/4963 [==============================] - 1s 110us/step - loss: 0.0459 - coeff_determination: 0.9322 - val_loss: 0.0450 - val_coeff_determination: 0.9299\n",
      "Epoch 18/150\n",
      "4963/4963 [==============================] - 0s 100us/step - loss: 0.0447 - coeff_determination: 0.9347 - val_loss: 0.0437 - val_coeff_determination: 0.9329\n",
      "Epoch 19/150\n",
      "4963/4963 [==============================] - 1s 108us/step - loss: 0.0431 - coeff_determination: 0.9345 - val_loss: 0.0425 - val_coeff_determination: 0.9341\n",
      "Epoch 20/150\n",
      "4963/4963 [==============================] - 0s 100us/step - loss: 0.0415 - coeff_determination: 0.9392 - val_loss: 0.0417 - val_coeff_determination: 0.9347\n",
      "Epoch 21/150\n",
      "4963/4963 [==============================] - 0s 98us/step - loss: 0.0396 - coeff_determination: 0.9409 - val_loss: 0.0388 - val_coeff_determination: 0.9389\n",
      "Epoch 22/150\n",
      "4963/4963 [==============================] - 0s 98us/step - loss: 0.0377 - coeff_determination: 0.9434 - val_loss: 0.0374 - val_coeff_determination: 0.9406\n",
      "Epoch 23/150\n",
      "4963/4963 [==============================] - 0s 95us/step - loss: 0.0361 - coeff_determination: 0.9465 - val_loss: 0.0352 - val_coeff_determination: 0.9448\n",
      "Epoch 24/150\n",
      "4963/4963 [==============================] - 0s 100us/step - loss: 0.0343 - coeff_determination: 0.9499 - val_loss: 0.0341 - val_coeff_determination: 0.9463\n",
      "Epoch 25/150\n",
      "4963/4963 [==============================] - 0s 94us/step - loss: 0.0329 - coeff_determination: 0.9507 - val_loss: 0.0337 - val_coeff_determination: 0.9464\n",
      "Epoch 26/150\n",
      "4963/4963 [==============================] - 0s 95us/step - loss: 0.0320 - coeff_determination: 0.9535 - val_loss: 0.0318 - val_coeff_determination: 0.9497\n",
      "Epoch 27/150\n",
      "4963/4963 [==============================] - 0s 96us/step - loss: 0.0310 - coeff_determination: 0.9546 - val_loss: 0.0316 - val_coeff_determination: 0.9498\n",
      "Epoch 28/150\n",
      "4963/4963 [==============================] - 0s 97us/step - loss: 0.0303 - coeff_determination: 0.9544 - val_loss: 0.0303 - val_coeff_determination: 0.9515\n",
      "Epoch 29/150\n",
      "4963/4963 [==============================] - 0s 95us/step - loss: 0.0300 - coeff_determination: 0.9531 - val_loss: 0.0293 - val_coeff_determination: 0.9531\n",
      "Epoch 30/150\n",
      "4963/4963 [==============================] - 0s 97us/step - loss: 0.0294 - coeff_determination: 0.9535 - val_loss: 0.0291 - val_coeff_determination: 0.9534\n",
      "Epoch 31/150\n",
      "4963/4963 [==============================] - 0s 94us/step - loss: 0.0289 - coeff_determination: 0.9564 - val_loss: 0.0292 - val_coeff_determination: 0.9530\n",
      "Epoch 32/150\n",
      "4963/4963 [==============================] - 0s 96us/step - loss: 0.0285 - coeff_determination: 0.9527 - val_loss: 0.0280 - val_coeff_determination: 0.9552\n",
      "Epoch 33/150\n",
      "4963/4963 [==============================] - 0s 97us/step - loss: 0.0281 - coeff_determination: 0.9579 - val_loss: 0.0283 - val_coeff_determination: 0.9544\n",
      "Epoch 34/150\n",
      "4963/4963 [==============================] - 0s 95us/step - loss: 0.0279 - coeff_determination: 0.9570 - val_loss: 0.0271 - val_coeff_determination: 0.9568\n",
      "Epoch 35/150\n",
      "4963/4963 [==============================] - 0s 96us/step - loss: 0.0276 - coeff_determination: 0.9555 - val_loss: 0.0272 - val_coeff_determination: 0.9560\n",
      "Epoch 36/150\n",
      "4963/4963 [==============================] - 0s 92us/step - loss: 0.0272 - coeff_determination: 0.9599 - val_loss: 0.0267 - val_coeff_determination: 0.9572\n",
      "Epoch 37/150\n",
      "4963/4963 [==============================] - 0s 92us/step - loss: 0.0269 - coeff_determination: 0.9611 - val_loss: 0.0265 - val_coeff_determination: 0.9572\n",
      "Epoch 38/150\n",
      "4963/4963 [==============================] - 0s 92us/step - loss: 0.0266 - coeff_determination: 0.9610 - val_loss: 0.0269 - val_coeff_determination: 0.9566\n",
      "Epoch 39/150\n",
      "4963/4963 [==============================] - 0s 92us/step - loss: 0.0263 - coeff_determination: 0.9615 - val_loss: 0.0262 - val_coeff_determination: 0.9582\n",
      "Epoch 40/150\n",
      "4963/4963 [==============================] - 0s 98us/step - loss: 0.0257 - coeff_determination: 0.9604 - val_loss: 0.0248 - val_coeff_determination: 0.9601\n",
      "Epoch 41/150\n",
      "4963/4963 [==============================] - 0s 97us/step - loss: 0.0257 - coeff_determination: 0.9614 - val_loss: 0.0242 - val_coeff_determination: 0.9611\n",
      "Epoch 42/150\n",
      "4963/4963 [==============================] - 1s 118us/step - loss: 0.0253 - coeff_determination: 0.9624 - val_loss: 0.0253 - val_coeff_determination: 0.9590\n",
      "Epoch 43/150\n",
      "4963/4963 [==============================] - 0s 95us/step - loss: 0.0251 - coeff_determination: 0.9632 - val_loss: 0.0238 - val_coeff_determination: 0.9617\n",
      "Epoch 44/150\n",
      "4963/4963 [==============================] - 1s 101us/step - loss: 0.0249 - coeff_determination: 0.9630 - val_loss: 0.0234 - val_coeff_determination: 0.9623\n",
      "Epoch 45/150\n",
      "4963/4963 [==============================] - 1s 104us/step - loss: 0.0246 - coeff_determination: 0.9609 - val_loss: 0.0237 - val_coeff_determination: 0.9617\n",
      "Epoch 46/150\n",
      "4963/4963 [==============================] - 0s 101us/step - loss: 0.0242 - coeff_determination: 0.9622 - val_loss: 0.0234 - val_coeff_determination: 0.9623\n",
      "Epoch 47/150\n",
      "4963/4963 [==============================] - 0s 98us/step - loss: 0.0239 - coeff_determination: 0.9645 - val_loss: 0.0238 - val_coeff_determination: 0.9615\n",
      "Epoch 48/150\n",
      "4963/4963 [==============================] - 0s 98us/step - loss: 0.0240 - coeff_determination: 0.9650 - val_loss: 0.0222 - val_coeff_determination: 0.9642\n",
      "Epoch 49/150\n",
      "4963/4963 [==============================] - 0s 96us/step - loss: 0.0236 - coeff_determination: 0.9655 - val_loss: 0.0221 - val_coeff_determination: 0.9646\n",
      "Epoch 50/150\n",
      "4963/4963 [==============================] - 0s 96us/step - loss: 0.0236 - coeff_determination: 0.9649 - val_loss: 0.0232 - val_coeff_determination: 0.9626\n",
      "Epoch 51/150\n",
      "4963/4963 [==============================] - 0s 93us/step - loss: 0.0232 - coeff_determination: 0.9659 - val_loss: 0.0219 - val_coeff_determination: 0.9649\n",
      "Epoch 52/150\n",
      "4963/4963 [==============================] - 0s 92us/step - loss: 0.0230 - coeff_determination: 0.9650 - val_loss: 0.0223 - val_coeff_determination: 0.9642\n",
      "Epoch 53/150\n",
      "4963/4963 [==============================] - 0s 93us/step - loss: 0.0228 - coeff_determination: 0.9648 - val_loss: 0.0221 - val_coeff_determination: 0.9645\n",
      "Epoch 54/150\n",
      "4963/4963 [==============================] - 0s 97us/step - loss: 0.0227 - coeff_determination: 0.9632 - val_loss: 0.0214 - val_coeff_determination: 0.9657\n",
      "Epoch 55/150\n",
      "4963/4963 [==============================] - 0s 93us/step - loss: 0.0224 - coeff_determination: 0.9657 - val_loss: 0.0216 - val_coeff_determination: 0.9651\n",
      "Epoch 56/150\n",
      "4963/4963 [==============================] - 0s 92us/step - loss: 0.0222 - coeff_determination: 0.9672 - val_loss: 0.0221 - val_coeff_determination: 0.9644\n",
      "Epoch 57/150\n",
      "4963/4963 [==============================] - 0s 93us/step - loss: 0.0221 - coeff_determination: 0.9674 - val_loss: 0.0211 - val_coeff_determination: 0.9662\n",
      "Epoch 58/150\n",
      "4963/4963 [==============================] - 0s 93us/step - loss: 0.0219 - coeff_determination: 0.9676 - val_loss: 0.0218 - val_coeff_determination: 0.9649\n",
      "Epoch 59/150\n",
      "4963/4963 [==============================] - 0s 91us/step - loss: 0.0221 - coeff_determination: 0.9660 - val_loss: 0.0204 - val_coeff_determination: 0.9672\n",
      "Epoch 60/150\n",
      "4963/4963 [==============================] - 0s 93us/step - loss: 0.0218 - coeff_determination: 0.9656 - val_loss: 0.0209 - val_coeff_determination: 0.9662\n",
      "Epoch 61/150\n",
      "4963/4963 [==============================] - 0s 92us/step - loss: 0.0215 - coeff_determination: 0.9676 - val_loss: 0.0205 - val_coeff_determination: 0.9671\n",
      "Epoch 62/150\n",
      "4963/4963 [==============================] - 0s 93us/step - loss: 0.0216 - coeff_determination: 0.9656 - val_loss: 0.0201 - val_coeff_determination: 0.9677\n",
      "Epoch 63/150\n",
      "4963/4963 [==============================] - 0s 92us/step - loss: 0.0216 - coeff_determination: 0.9680 - val_loss: 0.0219 - val_coeff_determination: 0.9644\n",
      "Epoch 64/150\n",
      "4963/4963 [==============================] - 0s 93us/step - loss: 0.0215 - coeff_determination: 0.9680 - val_loss: 0.0203 - val_coeff_determination: 0.9672\n",
      "Epoch 65/150\n",
      "4963/4963 [==============================] - 0s 92us/step - loss: 0.0213 - coeff_determination: 0.9675 - val_loss: 0.0197 - val_coeff_determination: 0.9682\n",
      "Epoch 66/150\n",
      "4963/4963 [==============================] - 0s 94us/step - loss: 0.0211 - coeff_determination: 0.9660 - val_loss: 0.0208 - val_coeff_determination: 0.9664\n",
      "Epoch 67/150\n",
      "4963/4963 [==============================] - 0s 93us/step - loss: 0.0210 - coeff_determination: 0.9692 - val_loss: 0.0195 - val_coeff_determination: 0.9685\n",
      "Epoch 68/150\n",
      "4963/4963 [==============================] - 0s 93us/step - loss: 0.0211 - coeff_determination: 0.9665 - val_loss: 0.0192 - val_coeff_determination: 0.9690\n",
      "Epoch 69/150\n",
      "4963/4963 [==============================] - 0s 92us/step - loss: 0.0210 - coeff_determination: 0.9681 - val_loss: 0.0191 - val_coeff_determination: 0.9692\n",
      "Epoch 70/150\n",
      "4963/4963 [==============================] - 0s 92us/step - loss: 0.0210 - coeff_determination: 0.9673 - val_loss: 0.0190 - val_coeff_determination: 0.9694\n",
      "Epoch 71/150\n",
      "4963/4963 [==============================] - 1s 101us/step - loss: 0.0207 - coeff_determination: 0.9691 - val_loss: 0.0195 - val_coeff_determination: 0.9685\n",
      "Epoch 72/150\n",
      "4963/4963 [==============================] - 0s 100us/step - loss: 0.0207 - coeff_determination: 0.9687 - val_loss: 0.0189 - val_coeff_determination: 0.9695\n",
      "Epoch 73/150\n",
      "4963/4963 [==============================] - 0s 98us/step - loss: 0.0207 - coeff_determination: 0.9684 - val_loss: 0.0189 - val_coeff_determination: 0.9695\n",
      "Epoch 74/150\n",
      "4963/4963 [==============================] - 0s 96us/step - loss: 0.0204 - coeff_determination: 0.9697 - val_loss: 0.0185 - val_coeff_determination: 0.9701\n",
      "Epoch 75/150\n",
      "4963/4963 [==============================] - 0s 98us/step - loss: 0.0203 - coeff_determination: 0.9703 - val_loss: 0.0195 - val_coeff_determination: 0.9688\n",
      "Epoch 76/150\n",
      "4963/4963 [==============================] - 1s 103us/step - loss: 0.0205 - coeff_determination: 0.9693 - val_loss: 0.0192 - val_coeff_determination: 0.9691\n",
      "Epoch 77/150\n",
      "4963/4963 [==============================] - 1s 102us/step - loss: 0.0204 - coeff_determination: 0.9694 - val_loss: 0.0185 - val_coeff_determination: 0.9702\n",
      "Epoch 78/150\n",
      "4963/4963 [==============================] - 1s 106us/step - loss: 0.0201 - coeff_determination: 0.9673 - val_loss: 0.0187 - val_coeff_determination: 0.9700\n",
      "Epoch 79/150\n",
      "4963/4963 [==============================] - 1s 103us/step - loss: 0.0201 - coeff_determination: 0.9686 - val_loss: 0.0184 - val_coeff_determination: 0.9704\n",
      "Epoch 80/150\n",
      "4963/4963 [==============================] - 1s 105us/step - loss: 0.0201 - coeff_determination: 0.9689 - val_loss: 0.0189 - val_coeff_determination: 0.9694\n",
      "Epoch 81/150\n",
      "4963/4963 [==============================] - 1s 106us/step - loss: 0.0199 - coeff_determination: 0.9704 - val_loss: 0.0189 - val_coeff_determination: 0.9697\n",
      "Epoch 82/150\n",
      "4963/4963 [==============================] - 1s 108us/step - loss: 0.0200 - coeff_determination: 0.9681 - val_loss: 0.0181 - val_coeff_determination: 0.9708\n",
      "Epoch 83/150\n",
      "4963/4963 [==============================] - 1s 104us/step - loss: 0.0198 - coeff_determination: 0.9705 - val_loss: 0.0182 - val_coeff_determination: 0.9706\n",
      "Epoch 84/150\n",
      "4963/4963 [==============================] - 1s 105us/step - loss: 0.0198 - coeff_determination: 0.9700 - val_loss: 0.0183 - val_coeff_determination: 0.9704\n",
      "Epoch 85/150\n",
      "4963/4963 [==============================] - 0s 100us/step - loss: 0.0197 - coeff_determination: 0.9696 - val_loss: 0.0178 - val_coeff_determination: 0.9714\n",
      "Epoch 86/150\n",
      "4963/4963 [==============================] - 0s 97us/step - loss: 0.0196 - coeff_determination: 0.9699 - val_loss: 0.0180 - val_coeff_determination: 0.9711\n",
      "Epoch 87/150\n",
      "4963/4963 [==============================] - 0s 99us/step - loss: 0.0196 - coeff_determination: 0.9695 - val_loss: 0.0178 - val_coeff_determination: 0.9714\n",
      "Epoch 88/150\n",
      "4963/4963 [==============================] - 0s 94us/step - loss: 0.0196 - coeff_determination: 0.9702 - val_loss: 0.0174 - val_coeff_determination: 0.9718\n",
      "Epoch 89/150\n",
      "4963/4963 [==============================] - 0s 93us/step - loss: 0.0197 - coeff_determination: 0.9701 - val_loss: 0.0189 - val_coeff_determination: 0.9694\n",
      "Epoch 90/150\n",
      "4963/4963 [==============================] - 0s 95us/step - loss: 0.0195 - coeff_determination: 0.9719 - val_loss: 0.0175 - val_coeff_determination: 0.9718\n",
      "Epoch 91/150\n",
      "4963/4963 [==============================] - 0s 94us/step - loss: 0.0194 - coeff_determination: 0.9702 - val_loss: 0.0173 - val_coeff_determination: 0.9722\n",
      "Epoch 92/150\n",
      "4963/4963 [==============================] - 0s 93us/step - loss: 0.0193 - coeff_determination: 0.9707 - val_loss: 0.0173 - val_coeff_determination: 0.9722\n",
      "Epoch 93/150\n",
      "4963/4963 [==============================] - 0s 93us/step - loss: 0.0193 - coeff_determination: 0.9714 - val_loss: 0.0180 - val_coeff_determination: 0.9710\n",
      "Epoch 94/150\n",
      "4963/4963 [==============================] - 0s 95us/step - loss: 0.0192 - coeff_determination: 0.9712 - val_loss: 0.0180 - val_coeff_determination: 0.9710\n",
      "Epoch 95/150\n",
      "4963/4963 [==============================] - 0s 93us/step - loss: 0.0191 - coeff_determination: 0.9690 - val_loss: 0.0173 - val_coeff_determination: 0.9720\n",
      "Epoch 96/150\n",
      "4963/4963 [==============================] - 0s 94us/step - loss: 0.0191 - coeff_determination: 0.9696 - val_loss: 0.0176 - val_coeff_determination: 0.9717\n",
      "Epoch 97/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4963/4963 [==============================] - 0s 96us/step - loss: 0.0190 - coeff_determination: 0.9723 - val_loss: 0.0168 - val_coeff_determination: 0.9730\n",
      "Epoch 98/150\n",
      "4963/4963 [==============================] - 0s 95us/step - loss: 0.0192 - coeff_determination: 0.9710 - val_loss: 0.0169 - val_coeff_determination: 0.9729\n",
      "Epoch 99/150\n",
      "4963/4963 [==============================] - 0s 94us/step - loss: 0.0189 - coeff_determination: 0.9722 - val_loss: 0.0171 - val_coeff_determination: 0.9724\n",
      "Epoch 100/150\n",
      "4963/4963 [==============================] - 0s 94us/step - loss: 0.0190 - coeff_determination: 0.9714 - val_loss: 0.0168 - val_coeff_determination: 0.9728\n",
      "Epoch 101/150\n",
      "4963/4963 [==============================] - 0s 95us/step - loss: 0.0189 - coeff_determination: 0.9694 - val_loss: 0.0166 - val_coeff_determination: 0.9733\n",
      "Epoch 102/150\n",
      "4963/4963 [==============================] - 0s 93us/step - loss: 0.0188 - coeff_determination: 0.9724 - val_loss: 0.0166 - val_coeff_determination: 0.9734\n",
      "Epoch 103/150\n",
      "4963/4963 [==============================] - 0s 94us/step - loss: 0.0187 - coeff_determination: 0.9724 - val_loss: 0.0170 - val_coeff_determination: 0.9725\n",
      "Epoch 104/150\n",
      "4963/4963 [==============================] - 0s 96us/step - loss: 0.0186 - coeff_determination: 0.9716 - val_loss: 0.0164 - val_coeff_determination: 0.9736\n",
      "Epoch 105/150\n",
      "4963/4963 [==============================] - 0s 98us/step - loss: 0.0187 - coeff_determination: 0.9711 - val_loss: 0.0164 - val_coeff_determination: 0.9735\n",
      "Epoch 106/150\n",
      "4963/4963 [==============================] - 0s 99us/step - loss: 0.0186 - coeff_determination: 0.9704 - val_loss: 0.0165 - val_coeff_determination: 0.9735\n",
      "Epoch 107/150\n",
      "4963/4963 [==============================] - 0s 96us/step - loss: 0.0186 - coeff_determination: 0.9700 - val_loss: 0.0166 - val_coeff_determination: 0.9732\n",
      "Epoch 108/150\n",
      "4963/4963 [==============================] - 0s 97us/step - loss: 0.0187 - coeff_determination: 0.9689 - val_loss: 0.0165 - val_coeff_determination: 0.9735\n",
      "Epoch 109/150\n",
      "4963/4963 [==============================] - 0s 98us/step - loss: 0.0185 - coeff_determination: 0.9722 - val_loss: 0.0162 - val_coeff_determination: 0.9738\n",
      "Epoch 110/150\n",
      "4963/4963 [==============================] - 0s 97us/step - loss: 0.0183 - coeff_determination: 0.9708 - val_loss: 0.0165 - val_coeff_determination: 0.9735\n",
      "Epoch 111/150\n",
      "4963/4963 [==============================] - 0s 95us/step - loss: 0.0184 - coeff_determination: 0.9716 - val_loss: 0.0169 - val_coeff_determination: 0.9727\n",
      "Epoch 112/150\n",
      "4963/4963 [==============================] - 0s 96us/step - loss: 0.0184 - coeff_determination: 0.9715 - val_loss: 0.0169 - val_coeff_determination: 0.9728\n",
      "Epoch 113/150\n",
      "4963/4963 [==============================] - 0s 95us/step - loss: 0.0185 - coeff_determination: 0.9734 - val_loss: 0.0162 - val_coeff_determination: 0.9739\n",
      "Epoch 114/150\n",
      "4963/4963 [==============================] - 0s 98us/step - loss: 0.0183 - coeff_determination: 0.9718 - val_loss: 0.0161 - val_coeff_determination: 0.9743\n",
      "Epoch 115/150\n",
      "4963/4963 [==============================] - 0s 94us/step - loss: 0.0183 - coeff_determination: 0.9728 - val_loss: 0.0160 - val_coeff_determination: 0.9743\n",
      "Epoch 116/150\n",
      "4963/4963 [==============================] - 0s 95us/step - loss: 0.0183 - coeff_determination: 0.9730 - val_loss: 0.0166 - val_coeff_determination: 0.9733\n",
      "Epoch 117/150\n",
      "4963/4963 [==============================] - 0s 95us/step - loss: 0.0181 - coeff_determination: 0.9728 - val_loss: 0.0164 - val_coeff_determination: 0.9734\n",
      "Epoch 118/150\n",
      "4963/4963 [==============================] - 0s 93us/step - loss: 0.0181 - coeff_determination: 0.9715 - val_loss: 0.0159 - val_coeff_determination: 0.9745\n",
      "Epoch 119/150\n",
      "4963/4963 [==============================] - 0s 93us/step - loss: 0.0179 - coeff_determination: 0.9729 - val_loss: 0.0159 - val_coeff_determination: 0.9743\n",
      "Epoch 120/150\n",
      "4963/4963 [==============================] - 0s 97us/step - loss: 0.0181 - coeff_determination: 0.9737 - val_loss: 0.0156 - val_coeff_determination: 0.9750\n",
      "Epoch 121/150\n",
      "4963/4963 [==============================] - 0s 94us/step - loss: 0.0180 - coeff_determination: 0.9728 - val_loss: 0.0159 - val_coeff_determination: 0.9745\n",
      "Epoch 122/150\n",
      "4963/4963 [==============================] - 0s 97us/step - loss: 0.0180 - coeff_determination: 0.9717 - val_loss: 0.0158 - val_coeff_determination: 0.9746\n",
      "Epoch 123/150\n",
      "4963/4963 [==============================] - 0s 99us/step - loss: 0.0179 - coeff_determination: 0.9745 - val_loss: 0.0165 - val_coeff_determination: 0.9732\n",
      "Epoch 124/150\n",
      "4963/4963 [==============================] - 1s 102us/step - loss: 0.0179 - coeff_determination: 0.9725 - val_loss: 0.0156 - val_coeff_determination: 0.9749\n",
      "Epoch 125/150\n",
      "4963/4963 [==============================] - 1s 103us/step - loss: 0.0177 - coeff_determination: 0.9740 - val_loss: 0.0157 - val_coeff_determination: 0.9747\n",
      "Epoch 126/150\n",
      "4963/4963 [==============================] - 0s 95us/step - loss: 0.0178 - coeff_determination: 0.9736 - val_loss: 0.0154 - val_coeff_determination: 0.9753\n",
      "Epoch 127/150\n",
      "4963/4963 [==============================] - 1s 102us/step - loss: 0.0178 - coeff_determination: 0.9728 - val_loss: 0.0153 - val_coeff_determination: 0.9753\n",
      "Epoch 128/150\n",
      "4963/4963 [==============================] - 0s 92us/step - loss: 0.0178 - coeff_determination: 0.9725 - val_loss: 0.0155 - val_coeff_determination: 0.9751\n",
      "Epoch 129/150\n",
      "4963/4963 [==============================] - 0s 94us/step - loss: 0.0177 - coeff_determination: 0.9722 - val_loss: 0.0161 - val_coeff_determination: 0.9740\n",
      "Epoch 130/150\n",
      "4963/4963 [==============================] - 0s 95us/step - loss: 0.0176 - coeff_determination: 0.9728 - val_loss: 0.0155 - val_coeff_determination: 0.9751\n",
      "Epoch 131/150\n",
      "4963/4963 [==============================] - 0s 96us/step - loss: 0.0177 - coeff_determination: 0.9720 - val_loss: 0.0156 - val_coeff_determination: 0.9748\n",
      "Epoch 132/150\n",
      "4963/4963 [==============================] - 0s 93us/step - loss: 0.0175 - coeff_determination: 0.9723 - val_loss: 0.0150 - val_coeff_determination: 0.9761\n",
      "Epoch 133/150\n",
      "4963/4963 [==============================] - 0s 93us/step - loss: 0.0175 - coeff_determination: 0.9736 - val_loss: 0.0151 - val_coeff_determination: 0.9756\n",
      "Epoch 134/150\n",
      "4963/4963 [==============================] - 0s 92us/step - loss: 0.0175 - coeff_determination: 0.9742 - val_loss: 0.0154 - val_coeff_determination: 0.9754\n",
      "Epoch 135/150\n",
      "4963/4963 [==============================] - 0s 93us/step - loss: 0.0175 - coeff_determination: 0.9749 - val_loss: 0.0151 - val_coeff_determination: 0.9757\n",
      "Epoch 136/150\n",
      "4963/4963 [==============================] - 1s 110us/step - loss: 0.0174 - coeff_determination: 0.9741 - val_loss: 0.0158 - val_coeff_determination: 0.9743\n",
      "Epoch 137/150\n",
      "4963/4963 [==============================] - 1s 106us/step - loss: 0.0173 - coeff_determination: 0.9735 - val_loss: 0.0151 - val_coeff_determination: 0.9758\n",
      "Epoch 138/150\n",
      "4963/4963 [==============================] - 1s 104us/step - loss: 0.0174 - coeff_determination: 0.9724 - val_loss: 0.0150 - val_coeff_determination: 0.9757\n",
      "Epoch 139/150\n",
      "4963/4963 [==============================] - 1s 101us/step - loss: 0.0174 - coeff_determination: 0.9736 - val_loss: 0.0151 - val_coeff_determination: 0.9757\n",
      "Epoch 140/150\n",
      "4963/4963 [==============================] - 0s 92us/step - loss: 0.0173 - coeff_determination: 0.9724 - val_loss: 0.0148 - val_coeff_determination: 0.9762\n",
      "Epoch 141/150\n",
      "4963/4963 [==============================] - 0s 90us/step - loss: 0.0172 - coeff_determination: 0.9747 - val_loss: 0.0150 - val_coeff_determination: 0.9757\n",
      "Epoch 142/150\n",
      "4963/4963 [==============================] - 0s 90us/step - loss: 0.0172 - coeff_determination: 0.9738 - val_loss: 0.0151 - val_coeff_determination: 0.9756\n",
      "Epoch 143/150\n",
      "4963/4963 [==============================] - 0s 96us/step - loss: 0.0171 - coeff_determination: 0.9729 - val_loss: 0.0150 - val_coeff_determination: 0.9759\n",
      "Epoch 144/150\n",
      "4963/4963 [==============================] - 0s 98us/step - loss: 0.0173 - coeff_determination: 0.9737 - val_loss: 0.0145 - val_coeff_determination: 0.9767\n",
      "Epoch 145/150\n",
      "4963/4963 [==============================] - 1s 102us/step - loss: 0.0171 - coeff_determination: 0.9748 - val_loss: 0.0152 - val_coeff_determination: 0.9756\n",
      "Epoch 146/150\n",
      "4963/4963 [==============================] - 0s 99us/step - loss: 0.0172 - coeff_determination: 0.9740 - val_loss: 0.0151 - val_coeff_determination: 0.9759\n",
      "Epoch 147/150\n",
      "4963/4963 [==============================] - 1s 104us/step - loss: 0.0172 - coeff_determination: 0.9736 - val_loss: 0.0145 - val_coeff_determination: 0.9768\n",
      "Epoch 148/150\n",
      "4963/4963 [==============================] - 0s 99us/step - loss: 0.0170 - coeff_determination: 0.9723 - val_loss: 0.0149 - val_coeff_determination: 0.9760\n",
      "Epoch 149/150\n",
      "4963/4963 [==============================] - 1s 105us/step - loss: 0.0169 - coeff_determination: 0.9746 - val_loss: 0.0157 - val_coeff_determination: 0.9746\n",
      "Epoch 150/150\n",
      "4963/4963 [==============================] - 1s 102us/step - loss: 0.0169 - coeff_determination: 0.9743 - val_loss: 0.0148 - val_coeff_determination: 0.9760\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(20,input_dim=3,activation='tanh'))\n",
    "model.add(keras.layers.Dense(1,activation='linear'))\n",
    "                \n",
    "                \n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=[coeff_determination])\n",
    "history = model.fit(X_train,Y_train,epochs=150, batch_size=10,validation_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XmUXGd55/HvU2vve2ttyWrbsrG8SUYYE5PEiROQDLEhk3Fs8ITMMDEzCQmZ4TDYQExgZnLCZA5hyLAGSNjBOBCUQQRjYrMEvMjCeF8kWZa6tXW3eq3u2p/5o67a5Xa3WrK6+lZ3/T7n1Omqe29VPX2lql+/73vve83dERERAYiEXYCIiFQPhYKIiExTKIiIyDSFgoiITFMoiIjINIWCiIhMUyiIzGBmf29m/+MUt91vZr8xx7p6M/snMxs1s2+Y2ZvN7M7TrOU9ZvaZ03mOyJmIhV2AyDL2O8BKoNPd88GyL59YaWYObHT3PcHjq4AvuXvPiW3c/S8Wr1wRtRREKuks4OmyQBCpegoFWZKCbpt3mdnDZpYys8+a2Uoz+66ZjZvZXWbWXrb9tWb2mJmNmNk9ZnZB2botZrY7eN7XgboZ7/V6M3soeO5PzeySU6jvA8BtwO+a2YSZvdXMft/MfhKs/1Gw6S+C9W8BvgusCR5PmNkaM/tzM/tS8JwNZuZm9hYzO2Bmg2b23rL3rDezz5vZsJk9YWb/zcz6XvpellqkUJCl7N8AvwmcB/wWpS/V9wDdlP5v/wmAmZ0HfBX402DdTuCfzCxhZgngH4EvAh3AN4LXJXjuFuBzwNuATuBTwA4zS56sMHd/P/AXwNfdvcndPztj/a8Edy8N1n8e2A4cCh43ufuhOV7+1cD5wNXAbWUB935gA3B2sF9uOlmNIrNRKMhS9jfuftTd+4EfA/e5+8/dPQ18C9gSbPe7wHfc/fvungP+N1AP/BJwBRAHPuLuOXe/A3ig7D1uBj7l7ve5eyH48s4EzwvLB9x9yt1/AfwCuDRYfj3wF+4+7O59wEdDq1CWLA00y1J2tOz+1CyPm4L7a4DnTqxw96KZHQTWAgWg3184M+RzZffPAt5iZn9ctiwRvGZYjpTdn+SFv+fBsnXl90VOiVoKUgsOUfpyB8DMDFgH9AOHgbXBshPWl90/CPxPd28ruzW4+1crUOeZTll8GOgpe7zuDF9PapBCQWrB7cDrzOxqM4sD76TUBfRT4GdAHvgTM4ub2W8Dl5c992+B/2Rmr7SSRjN7nZk1L0BdRyn1/5c/7jSz1pf4ercDt5pZu5mtBd5+pgVK7VEoyLLn7k9RGnT9G2CQ0qD0b7l71t2zwG8Dvw8cpzT+8M2y5+4C/gD4v8AwsCfYdiH8OfD54Kim6939SUoD4vuCZafbRfVBoA94FrgLuINS+ImcMtNFdkSWJzP7z8AN7v6rYdciS4daCiLLhJmtNrMrzSxiZudT6ib7Vth1ydKio49Elo8EpfMoeoER4GvAx0OtSJYcdR+JiMg0dR+JiMi0Jdd91NXV5Rs2bAi7DBGRJeXBBx8cdPfu+bZbcqGwYcMGdu3aFXYZIiJLipk9N/9WFew+MrPPmdkxM3t0jvVmZh81sz3BTJeXVaoWERE5NZUcU/h7YNtJ1m8HNga3m4FPVLAWERE5BRULBXf/EaUzROdyHfAFL7kXaDOz1ZWqR0RE5hfmmMJaXjiLY1+w7PDpvlAul6Ovr490Or1QtVWluro6enp6iMfjYZciIsvUkhhoNrObKXUxsX79+het7+vro7m5mQ0bNvDCyS6XD3dnaGiIvr4+ent7wy5HRJapMM9T6OeFU/v2BMtexN0/7e5b3X1rd/eLj6hKp9N0dnYu20AAMDM6OzuXfWtIRMIVZijsAH4vOArpCmDU3U+76+iE5RwIJ9TC7ygi4apY95GZfRW4CugKLh7+fkqXPcTdP0npOrnXUJqKeBL495WqRUSWgGKx9DMy429Vd8hNgUUAh/QY5FIQb4R4PXgRzCDZQq7oxA0YP1R6XiQK2RRkxkqXMIpESq8TiUFDFzR2QyEL44dLrxNNwOQQjBwoLY/VQawOjyXJ5AtMpiYg0UTzmo3EY3EY2gtTxwEr1YBBMQ/ZCchnKEaTTHmM+vpGItF46TVzk5AahOw4ufpuUokuGpMx4hTBC6XnFwul371lDZP1q2FyiPjYAWJrL8U6z6noP0PFQsHdb5xnvQN/VKn3X0wjIyN85Stf4Q//8A9P63nXXHMNX/nKV2hra6tQZXJGCvnSz2jwMXEvfcHgUCzgmXFGJlKMxrqZ8jgdjQk6G+KQHsEnjhGPWPAFFC19YVgUIlHGs0X6h6dYHZ+ktTBEIZ/n4GiOjEdIJhI0FCepzw5BPk2+WCRikIhEKOYzpCcnyCZaSa95JcNpY3LPj2mY7KOjLkJjrEgxnyVvMVLJ1aQSHeSKEPc8vYlRWi2FR5OMZ/Ic799LcewwdVEnEXHyhTz5QoGYlb5U6+JGMgpTmRyT2TypSDOpaAstPk5bfpAoeSIWIWKGRYKfFiESMSKRCPlshmxmCscgXkcxWkfGEuQsSSGaxLNT1E8dpqk4TowCUc8ToUieKKPRDlKRZiIUqfM0bYXjxDw77z/XhDVyqNDGusgg9ad4GYkCUaIU5t3OgLrgdjoiQONJ1seB+T79DWX373/Zu7n8hvecZhWnZ0kMNFe7kZERPv7xj78oFPL5PLHY3Lt4586dlS6tKqQyeSYyeVLpHJNTU2TzBRoaG4lHIwyNZ5gaOUpzSyttLS0k41GSnqazMIBNHCVNnCeGI+wZi7JvFOpTB+mY2k+KRgaj3ZwXO8KFxadJJhMUGlcxOjHF+PAxWnycVYkphuKr+G7hFUyk82zO7qYnf4D24nEsliDTcQGTeSd+5CG680dpjuVIkiNSyBD3LBFKf7mOWTOpYoJOGyVBfvr3MqA9uB33JiI4BTIkLT/rfjihGXhZ2eMosOEU92X5F8yJww3yHiFHjBxRcsRoIstae/GXYtrjJMjTDEzQwTE6GfAoRTeKGBaJkXMoulEgAhgFGohHoSMySavvZ8ibeLiwjixxDIfS1z6GBzeImpPxGBniRIBkOkMd2eCWoc7GyVmcVN1FpGKtDE06U0UjmUzQHCvQURymycfJEyNFgucKzQwWGmlKRmmtjxOpb8Pi9WSnxsmlU4xmiuRyeS5rGaU3OcbP/FU8mllBQ12SzsYYGatnzOvI5J1cPk8ulyefz9GYO057foBMtJ7x+ArSBSOTmWKMRgZiq2hoaGJdc4QV9U5bvEBDMkZdfSPR3ATR4X1MprM8yyr6Mk2MpbMUi0VWNNcRj0c5mIoxVYxxyep6elujTE6mGEtNMTTlDOeiRJtX0NzSxobkON02SipT4Hi6yMhUgeF0kaGpIpPpHJe1TbC5JUW+voPj8TVcfPGWU/yf8tIpFBbALbfcwt69e9m8eTPxeJy6ujra29t58sknefrpp3nDG97AwYMHSafTvOMd7+Dmm28Gnp+yY2Jigu3bt/PqV7+an/70p6xdu5Zvf/vb1NfXL9rvMJHJs38wRd/wJJl8kVgkQq5QZCKTpz4eZXVznORkP9mjT3M8DU/Z2YyMp1g5dB/dmedoYoqGODS3dlBfV0dmYoSR1BR7x+PkMpO8KvIYF9pzxK1A0Y1nfRX93sWFkf102jhQ+nKLWfEFddUBW4LbXLIeJUqRqD0/4++INzLqjVxog1xqn51eftRWMGjtxApDnD/6AAYcjPdytPkCHpyAsXyUeF0jsUQ947kIEc9zVt0U7fE8z0TbGLVWcsVST0RdUxstjXV05gdozA4yVYgwUYwxmehiPNbBweE0h0cmaU5G6G6MUR+DeAQ6GqJ0NsTpz9Tz8Gg9rY31bFrVQFPMyWYzjNPASKSNQrSeeCxC0WEqWyASS9DY3EJrdoD2gQdoiBbp2PQrxFecx96BFMdTWZKxKMmY0VgYpz4/TCJqpHLGg8NJ9o0UaUxE6W6K88pzutnc3cRUrsDQRJaupiT1iSjFojOYyvDE4XH2DUxwSU8rm9e1E408P561peiMp/OMTuWmb6lsnqlsgcFUlmNjadZ1NPDaC1fR3hDn0EiaXLFIR0OCuniUojvJWIRY9NSGNN2dTL5IXTw65zbFohMJajwP+PVTemWZzZKbOnvr1q0+c+6jJ554ggsuuACAD/zTYzx+aGxB33PTmhbe/1sXzrl+//79vP71r+fRRx/lnnvu4XWvex2PPvro9KGjx48fp6Ojg6mpKV7xilfwwx/+kM7OzheEwrnnnsuuXbvYvHkz119/Pddeey033XTTi96r/HcFyOZL3QvRiL1oIPrg8UkeOjjCZetbWevHeGwgyxd2D7Mqs48LCs/Q3pSkobWbPc8dYLB/L7FiqYk+RZJxb6DNxum1I/TaEdbb0ZP+BTxpDRTcaPBJouakPIlblCYmKViMobZLGOncgtW1ECdP/dBjJFP9pLsuotB9IZn0JLnJUfLEmPIE+3Ot7Eu30NsWZVOH01Ofo8WmsLZ10HUeZMZhtI9i63oONZ7PaAby48fobmlg9arV5Imyd2CCluIYa479qNR1c86vQdMKoPRFMzA6TtygvbUFKH2x5ItOIqbJg2X5MbMH3X3rfNuppVABl19++QvOJfjoRz/Kt75VugDWwYMHeeaZZ+js7HzBc3p7e9m8eTMAL3/5y9m/f//0OncnV3AKxSJT2QK3/MPDPPbcEQZHUxQyKc6JHOL8SD+XJg9zTvQoiWIaK+YYz0dZQYRmOwA2yYXAh2ap92IgF01Aso6IQSQ/iRXzFKNJim0byLRewkD9etLNG6hbdR7tiSINg4+UQujsX4VVl9IQ9LsPT2Q4nppibUdz6S+7Qp6oF1gRS7LiNPbhvP9zAxFKxzL3ANAxvTwOvGxVC9ACa970oueZGSvaWl74WhEjEdERXlLbll0onOwv+sXS2Ph8z+8999zDXXfdxc9+9jMaGhq46qqrZj3XIJlMTt+PRqNMTk4ykc4xMZUmm57ECjkwJzc5wu898nY28ezzo1+BSW+i33tIRxvwRILVySItCdhv2/hJqoeXrWjgl9ZGSK48H+95BYNTBY4dPcK6NWto6Vzz/FEfwdEekViSSCRKjNkGy14z6+/e3pSkven536U0SLvs/puJLFv6tC6A5uZmxsfHZ103OjpKe3s7DQ0NPPnkk9x7771zvs5UtsBULs9YKk1qYpzo0NOssuCoi+D7eoIUL+vpgnNvhEQjxJLQtRG6X0ZD00o2znIuw8XBrZwB3a3QverFZ4hjBomGFy8XkWVPobAAOjs7ufLKK7nooouor69n5cqV0+u2bdvGJz/5SS644ALOP/98rrjiCtydE2M5E+kcB4ZSZPN5MgN7aWWKlsIQESZLg4wNa4kk6kvHTwMMJ7D/eFcYv6aI1IBlN9BcjXKFIulcgXSuQCE9QSw3TtIzJMgTo0DEihhQtCjFZCvRRAOWaIB4Q3BCzPOq/XcVkeqkgeYQZXIFxqeyWHqYSH6KmOdIkKOJPGalI7vz0SQFqyMXjZNMxCFWR6SujcjMszlFRBaRQmGBZXM5xo8dpJ1xolakQIRiNAGxRorxulIrINlMPBJFE2CLSLVRKCwgz4xjQ/vpJE+xrg2aVxCNNxDVRHYiskQoFBZKMQ9D+yh6lLGmDbS2toddkYjIaVMH9gLxyeMYRQbiq2lp0QR3IrI0qaWwENzx1BBTnqSpqVnXPRCRJUsthQUwMnCIT372CxynmcbE6eXsRz7yESYnJytUmYjI6VEoLICRw8/y8S98g8loC/HTnExNoSAi1UTdR2fKnVtu+x/sfa6PN/7mL3PNtteyYsUKbr/9djKZDG984xv5wAc+QCqV4vrrr6evr49CocCf/dmfcfToUQ4dOsSv/dqv0dXVxd133x32byMiNW75hcJ3b4Ejjyzsa666GLb/5ezr8hn+8j1/zM+fepaf3LuLB/71Hu644w7uv/9+3J1rr72WH/3oRwwMDLBmzRq+853vAKU5kVpbW/nwhz/M3XffTVdX18LWLCLyEqj76EzlSzOeuhuNySh33nknd955J1u2bOGyyy7jySef5JlnnuHiiy/m+9//Pu9+97v58Y9/TGtra8iFi4i82PJrKcz1F32lBKGAGYlYFHfn1ltv5W1ve9uLNt29ezc7d+7kfe97H1dffTW33Xbb4tYqIjIPtRTOkOcz1DU2M5lKAfDa176Wz33uc0xMTADQ39/PsWPHOHToEA0NDdx00028613vYvfu3cDJp90WEVlsy6+lsMg8l6axvZtXvupVXHTRRWzfvp03velNvOpVrwKgqamJL33pS+zZs4d3vetdRCIR4vE4n/jEJwC4+eab2bZtG2vWrNFAs4iETlNnnwl3/MjDDBWbqOtcT1Nd5ae409TZIvJSnOrU2eo+OhPFHOZFMsRJxqNhVyMicsYUCmciVxpkzlmCmC74LiLLwLIJhVC6wfKZ0s9Y3aLMd7TUuvpEZOlZFqFQV1fH0NDQ4n9p5tMUiBCLJyr+Vu7O0NAQdXV1FX8vEaldy+Loo56eHvr6+hgYGFjU9/WJY+TyBbJ1EcaPVH5X1tXV0dPTU/H3EZHatSxCIR6P09vbu+jvm/3Qb/GP45tY/ZbP8oqN3Yv+/iIiC21ZdB+FIj1GYmqAvb6GjSuaw65GRGRBKBRequH9AAzEVrOyJRluLSIiC0Sh8FIFoWAdG3SlNRFZNioaCma2zcyeMrM9ZnbLLOvXm9ndZvZzM3vYzK6pZD0LauQ5AJpWnRNyISIiC6dioWBmUeBjwHZgE3CjmW2asdn7gNvdfQtwA/DxStWz0DID+xj1BtasWh12KSIiC6aSLYXLgT3uvs/ds8DXgOtmbONAS3C/FThUwXoWVHbgWQ76Cs7qbAy7FBGRBVPJUFgLHCx73BcsK/fnwE1m1gfsBP54thcys5vNbJeZ7VrscxHmYiP7OeArOKuzIexSREQWTNgDzTcCf+/uPcA1wBfN7EU1ufun3X2ru2/t7q6C8wGKRepS/Rz0btZ3KBREZPmoZCj0A+vKHvcEy8q9FbgdwN1/BtQB1X+x4okjxDzL8cQaGpPL4vw/ERGgsqHwALDRzHrNLEFpIHnHjG0OAFcDmNkFlEKhOvqHTma4dORRvmV9yIWIiCysioWCu+eBtwPfA56gdJTRY2b2QTO7NtjsncAfmNkvgK8Cv+9LYSrQ4ByFaMfiT60hIlJJFe37cPedlAaQy5fdVnb/ceDKStZQCfmhfUTcaFqpUBCR5UUd4i/B5LF9TNBOT3db2KWIiCyosI8+WpKKQ/uDcxR05JGILC8KhZcgPn6Ag76C9R06cU1ElheFwunKpWnMHOOwraSrqfJXXBMRWUwKhdN19FEARprO0eyoIrLsKBRO18H7ABjr2hJyISIiC09HH50mP3g/h7yLtpU6cU1Elh+1FE5T4cB9PFjcSG9XU9iliIgsOIXC6RjtIzZxmN3FjWxep3MURGT5USicjoP3A/BE9HzOX9UccjEiIgtPoXA6+h4gQ4LkukuJRnTkkYgsPwqF01A4cB+/KJ7NpWetCLsUEZGKUCicqlwaO/Iwu4sbuWx9e9jViIhUhELhVO27m0gxx8+Km9iyXoPMIrI8KRRO1aP/wESkmcMdl9PWoOktRGR5Uiiciuwk/uRO/rn4Si49qwquES0iUiEKhVPxzPewXIp/yL6Sy3s7wq5GRKRiNM3FKRjd9XWy3gpn/RJv3LI27HJERCpGLYV5TI2PUPfsD7g7eiV/8+ZXEItql4nI8qVvuHk898B3SJJlwy/fQFdTMuxyREQqSqEwD9/7L0x4HWdf9uthlyIiUnEKhZNxZ8Wxf2V35GK6WjXXkYgsfwqFkzm+j87cYfa3XxF2JSIii0KhcBK5p+8CILP+V0OuRERkceiQ1JOYeuJODhVXsObsi8IuRURkUailMJd8lvr+n/Kj4iVsWtMSdjUiIotCoTCXI48QL0zyYOQSzupoCLsaEZFFoVCYy/CzpZ/d5xHRBXVEpEYoFOZQPF4Khc6ejSFXIiKyeDTQPIfJo/uY8lY2rtVV1kSkdqilMIf80LMc8BX0djWGXYqIyKKpaCiY2TYze8rM9pjZLXNsc72ZPW5mj5nZVypZz+mIjx3goHezqrUu7FJERBZNxbqPzCwKfAz4TaAPeMDMdrj742XbbARuBa5092Ezq46+mkKO+qkjHPRXsK1FoSAitaOSLYXLgT3uvs/ds8DXgOtmbPMHwMfcfRjA3Y9VsJ5TN9pHhAKDsdXUxaNhVyMismgqGQprgYNlj/uCZeXOA84zs381s3vNbNtsL2RmN5vZLjPbNTAwUKFyy4w8B8BUY0/l30tEpIqEPdAcAzYCVwE3An9rZm0zN3L3T7v7Vnff2t29CNdIHi6FQq71rMq/l4hIFalkKPQD68oe9wTLyvUBO9w95+7PAk9TColwDe8nT5REuy69KSK1pZKh8ACw0cx6zSwB3ADsmLHNP1JqJWBmXZS6k/ZVsKZTUhzeT793srJVh6OKSG2pWCi4ex54O/A94Angdnd/zMw+aGbXBpt9Dxgys8eBu4F3uftQpWo6Vfmh/RwormClDkcVkRpT0TOa3X0nsHPGstvK7jvwX4Nb1bCR5zjol7BKh6OKSI0Je6C5+mQmiKeH6PMVrFQoiEiNUSjMNHIAgAO+Qmczi0jNUSjMNFo6teJopJuOhkTIxYiILC6FwkyjfQBkG9foOgoiUnMUCjONHaJAhETrqrArERFZdAqFmcb6GbQOult1CU4RqT0KhRl8rJ9DxQ4deSQiNUmhMENxtJ/+YofOURCRmqRQKOeOjfVz2Dt0OKqI1CSFQrmpYSL5NIe9k+7mZNjViIgsupOGgplFzextZvbfzezKGeveV9nSQjBWmsT1sHfQ0ahzFESk9szXUvgU8KvAEPBRM/tw2brfrlhVYRk7BMBh76RdJ66JSA2aLxQud/c3uftHgFcCTWb2TTNLAsvvzK7gxLXD3kFrfTzkYkREFt98oTD957K75939ZuAh4F+ApkoWFoqxQxSJMhHv1LWZRaQmzRcKu2ZeN9ndPwj8HbChUkWFZqyf0VgnrQ0aZBaR2nTSUHD3m9z9n2dZ/hl3X379K2P9DEW7aNV4gojUqFM6JNXMaqMvZewQR+mivWH55Z2IyKmYNxTMrBn49iLUEi53GO3nULGdNoWCiNSo+c5TWA3cBXx6ccoJ0dQw5Kd4Lt9Om7qPRKRGzddS+DHwl+6+YzGKCVVw4tqz2TZ1H4lIzZovFIaBtYtRSOjGDgOUuo/q1VIQkdo0XyhcBWw3sz9ahFrCNTkIwCAtGlMQkZo13yGpKeBaYMvilBOiVCkUhr1ZYwoiUrNi823g7gXgPy5CLeGaHKIYiTNBvcYURKRmvaSps80sYmZvXuhiQjU5SCbRDphaCiJSs+Y7JLXFzG41s/9rZq+xkj8G9gHXL06Ji2TyOFPxdgCNKYhIzZqv++iLlI5A+hmlLqT3UJod9Q3u/lCFa1tcqUEmIi0AtGmGVBGpUfOFwtnufjGAmX0GOAysd/d0xStbbJNDjEZ6aU7GiEV1QToRqU3zffvlTtwJBpz7lmUgAEwOlo48alQrQURq13wthUvNbCy4b0B98NgAd/eWila3WAo5SI8ymGzWFddEpKadNBTcvTZmR508DsCxQhOtLWopiEjtqmjnuZltM7OnzGyPmd1yku3+jZm5mW2tZD1zmhwC4HCuUS0FEalpFQuF4BoMHwO2A5uAG81s0yzbNQPvAO6rVC3zCqa46M806HBUEalplWwpXA7scfd97p4FvgZcN8t2/x34EBDeAHbQUjiYbdCJayJS0yoZCmuBg2WP+5gx46qZXQasc/fvVLCO+QXzHg0VWzTFhYjUtNAOyDezCPBh4J2nsO3NZrbLzHYNDAwsfDHBQPMIjeo+EpGaVslQ6AfWlT3uCZad0AxcBNxjZvuBK4Adsw02u/un3X2ru2/t7u5e+EonB8knWskTU/eRiNS0SobCA8BGM+s1swRwAzB9BTd3H3X3Lnff4O4bgHuBa919VwVrmt3kENlEad4jHX0kIrWsYqHg7nng7cD3gCeA2939MTP7oJldW6n3fUlSg6TibQCsaE6GXIyISHjmvZ7CmXD3ncDOGctum2PbqypZy0lNHmfMSi2FriaFgojULs38BjA5yHFa6GxMkIhpl4hI7dI3oDtMDjFYaKRbXUciUuMUCplxKGQ5nGtiZUtd2NWIiIRKoXDibOZMvQaZRaTmKRSCUDiQblBLQURqnkIhmOJisNjEiha1FESktikUUqVpM4ZoVfeRiNQ8hULqGAAD3soKdR+JSI1TKEwMkIs1kiGhloKI1DyFQuoYqVgHgM5TEJGap1CYOMZIpI32hjjJWG1cklpEZC4KhdQAQ7TpcFQRERQKMHGMo8VmdR2JiFDhWVKrXiEHU8fpjzarpSAiQq23FIIT1w5kGnXkkYgINR8KpXMUjhVb1VIQEaHWQ2Gi7MQ1tRRERBQKAIPobGYREaj1UAi6jwa9ld6uxpCLEREJX22HwsQAGatjZVcnHY2JsKsREQldTYeCp44x4C1ctr497FJERKpCTYdCevgwx4otXHZWW9iliIhUhZoOhezoUQa9VS0FEZFATYdCdGqAkUg7561sDrsUEZGqULuhUMjTkB8l1rKKaMTCrkZEpCrUbChMjhwlgtPatSbsUkREqkbNhsLT+/YBsHLtupArERGpHjUbCkcPHwCgp+eskCsREakeNRsK6aFDALR2rQ25EhGR6lGzoVA38jRZYli7WgoiIifUbCh0pZ7hcGIDRONhlyIiUjVqMhTcnbNy+xhuOi/sUkREqkpFQ8HMtpnZU2a2x8xumWX9fzWzx83sYTP7gZktSl/OyEA/XTZKuvOCxXg7EZElo2KhYGZR4GPAdmATcKOZbZqx2c+Bre5+CXAH8L8qVU+543t3AxBbc8livJ2IyJJRyZbC5cAed9/n7lnga8B15Ru4+93uPhk8vBfoqWA90zL9DwPQumHzYrydiMiSUclQWAscLHvcFyyby1uB7862wsxuNrNdZrZrYGDgjAuLDjzGEW8rjK+fAAAKlklEQVRnzZpFySARkSWjKgaazewmYCvwV7Otd/dPu/tWd9/a3d19xu/XMvoUe2wDjcnYGb+WiMhyUslQ6AfK55DoCZa9gJn9BvBe4Fp3z1SwnpJ8hu70fo7Un1vxtxIRWWoqGQoPABvNrNfMEsANwI7yDcxsC/ApSoFwrIK1PG/waWIUGGt92aK8nYjIUlKxUHD3PPB24HvAE8Dt7v6YmX3QzK4NNvsroAn4hpk9ZGY75ni5BVM8/AgAhe6ZB0KJiEhFO9XdfSewc8ay28ru/0Yl3382k8/tJuoJmtaopSAiMlNVDDQvJu/fzeN+Fj1dutqaiMhMtRUKxQL1xx/nkWIv69obwq5GRKTq1FYoDD5DrDDFo95Ld3My7GpERKpObYXC4YcAeIxzaEhEQy5GRKT61FYoHHqIrCUZSKzHzMKuRkSk6tTWKb2HH6K/7lwarC7sSkREqlLttBSKBTj8MHtj59JSX1tZKCJyqmonFIb2QC7FU3YOLXW62pqIyGxqJxQOlQaZHy72KhREROZQO6GQT0N7L49lV6n7SERkDrUTCi9/C7zjIYbTRbUURETmUDuhAOQLRVLZAs0KBRGRWdVUKIyn8wDqPhIRmUNthoJaCiIis6qpUBhL5wBoqVcoiIjMprZCYSoIhTp1H4mIzKa2QiFoKWigWURkdrUVClMaaBYROZnaCgWNKYiInFSNhUIeM2hKqKUgIjKb2gqFqRzNyRiRiK6lICIym9oKhXROXUciIidRW6EwldeRRyIiJ1FboZDO6RwFEZGTqK1QmFL3kYjIydRUKIyn85r3SETkJGoqFEoDzeo+EhGZS82EQrHoTGQ00CwicjI1EwrjmTzumgxPRORkaiYUpmdI1UCziMicaicUTsx7pO4jEZE5VTQUzGybmT1lZnvM7JZZ1ifN7OvB+vvMbEOlatGlOEVE5lexUDCzKPAxYDuwCbjRzDbN2OytwLC7nwv8NfChStXz/AV21FIQEZlLJVsKlwN73H2fu2eBrwHXzdjmOuDzwf07gKvNrCKz1Y3p+swiIvOqZCisBQ6WPe4Lls26jbvngVGgc+YLmdnNZrbLzHYNDAy8pGKeH2hW95GIyFyWxECzu3/a3be6+9bu7u6X9Bo97fW89sKVNCUVCiIic6nkN2Q/sK7scU+wbLZt+swsBrQCQ5Uo5jUXruI1F66qxEuLiCwblWwpPABsNLNeM0sANwA7ZmyzA3hLcP93gH9xd69gTSIichIVaym4e97M3g58D4gCn3P3x8zsg8Aud98BfBb4opntAY5TCg4REQlJRTvY3X0nsHPGstvK7qeBf1vJGkRE5NQtiYFmERFZHAoFERGZplAQEZFpCgUREZmmUBARkWm21E4LMLMB4LmX+PQuYHABy6kE1bgwVOPCqPYaq70+qJ4az3L3eaeEWHKhcCbMbJe7bw27jpNRjQtDNS6Maq+x2uuDpVFjOXUfiYjINIWCiIhMq7VQ+HTYBZwC1bgwVOPCqPYaq70+WBo1TqupMQURETm5WmspiIjISSgURERkWs2EgpltM7OnzGyPmd0Sdj0AZrbOzO42s8fN7DEze0ewvMPMvm9mzwQ/20OuM2pmPzez/xc87jWz+4J9+fXgehlh1tdmZneY2ZNm9oSZvaoK9+F/Cf6NHzWzr5pZXdj70cw+Z2bHzOzRsmWz7jcr+WhQ68NmdlmINf5V8G/9sJl9y8zaytbdGtT4lJm9Nqway9a908zczLqCx6Hsx9NRE6FgZlHgY8B2YBNwo5ltCrcqAPLAO919E3AF8EdBXbcAP3D3jcAPgsdhegfwRNnjDwF/7e7nAsPAW0Op6nn/B/hnd38ZcCmlWqtmH5rZWuBPgK3ufhGl64vcQPj78e+BbTOWzbXftgMbg9vNwCdCrPH7wEXufgnwNHArQPDZuQG4MHjOx4PPfhg1YmbrgNcAB8oWh7UfT1lNhAJwObDH3fe5exb4GnBdyDXh7ofdfXdwf5zSl9laSrV9Ptjs88AbwqkQzKwHeB3wmeCxAb8O3BFsEnZ9rcCvULpgE+6edfcRqmgfBmJAfXDZ2QbgMCHvR3f/EaWLW5Wba79dB3zBS+4F2sxsdRg1uvud7p4PHt5L6VK/J2r8mrtn3P1ZYA+lz/6i1xj4a+C/AeVH84SyH09HrYTCWuBg2eO+YFnVMLMNwBbgPmClux8OVh0BVoZUFsBHKP3HLgaPO4GRsg9l2PuyFxgA/i7o4vqMmTVSRfvQ3fuB/03pL8bDwCjwINW1H0+Ya79V62foPwDfDe5XTY1mdh3Q7+6/mLGqamqcS62EQlUzsybgH4A/dfex8nXBNatDOW7YzF4PHHP3B8N4/1MUAy4DPuHuW4AUM7qKwtyHAEG//HWUAmwN0Mgs3Q3VJuz9Nh8zey+lLtgvh11LOTNrAN4D3DbfttWoVkKhH1hX9rgnWBY6M4tTCoQvu/s3g8VHTzQpg5/HQirvSuBaM9tPqcvt1yn137cF3SAQ/r7sA/rc/b7g8R2UQqJa9iHAbwDPuvuAu+eAb1Lat9W0H0+Ya79V1WfIzH4feD3wZn/+ZKtqqfEcSn8A/CL47PQAu81sFdVT45xqJRQeADYGR3skKA1G7Qi5phP9858FnnD3D5et2gG8Jbj/FuDbi10bgLvf6u497r6B0j77F3d/M3A38Dth1wfg7keAg2Z2frDoauBxqmQfBg4AV5hZQ/BvfqLGqtmPZebabzuA3wuOnrkCGC3rZlpUZraNUpfmte4+WbZqB3CDmSXNrJfSYO79i12fuz/i7ivcfUPw2ekDLgv+r1bNfpyTu9fEDbiG0pEKe4H3hl1PUNOrKTXPHwYeCm7XUOq3/wHwDHAX0FEFtV4F/L/g/tmUPmx7gG8AyZBr2wzsCvbjPwLt1bYPgQ8ATwKPAl8EkmHvR+CrlMY4cpS+uN46134DjNIRfHuBRygdSRVWjXso9cuf+Mx8smz79wY1PgVsD6vGGev3A11h7sfTuWmaCxERmVYr3UciInIKFAoiIjJNoSAiItMUCiIiMk2hICIi0xQKIovIzK6yYLZZkWqkUBARkWkKBZFZmNlNZna/mT1kZp+y0jUlJszsr4PrIvzAzLqDbTeb2b1l8/ufuAbBuWZ2l5n9wsx2m9k5wcs32fPXf/hycJazSFVQKIjMYGYXAL8LXOnum4EC8GZKE9ntcvcLgR8C7w+e8gXg3V6a3/+RsuVfBj7m7pcCv0TprFcozYb7p5Su7XE2pXmQRKpCbP5NRGrO1cDLgQeCP+LrKU0MVwS+HmzzJeCbwfUc2tz9h8HyzwPfMLNmYK27fwvA3dMAwevd7+59weOHgA3ATyr/a4nMT6Eg8mIGfN7db33BQrM/m7HdS50jJlN2v4A+h1JF1H0k8mI/AH7HzFbA9HWLz6L0eTkxq+mbgJ+4+ygwbGa/HCz/d8APvXQlvT4ze0PwGslgnn2Rqqa/UERmcPfHzex9wJ1mFqE0++UfUbqAz+XBumOUxh2gNMX0J4Mv/X3Avw+W/zvgU2b2weA1/u0i/hoiL4lmSRU5RWY24e5NYdchUknqPhIRkWlqKYiIyDS1FEREZJpCQUREpikURERkmkJBRESmKRRERGTa/we0eg587ibvmgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['coeff_determination'])\n",
    "plt.plot(history.history['val_coeff_determination'])\n",
    "plt.title('model fitting')\n",
    "plt.ylabel('R^2')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def coeff_determination(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1853/1853 [==============================] - 0s 13us/step\n",
      "[0.01620428961326247, 0.9815248924207507]\n",
      "['loss', 'coeff_determination']\n",
      "coeff_determination: 0.98\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test,Y_test)\n",
    "print (scores)\n",
    "print (model.metrics_names)\n",
    "print(\"%s: %.2f\" % (model.metrics_names[1], scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_train[:1000]\n",
    "Y_new = Y_train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-91-8afec8440656>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-91-8afec8440656>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    model.add(keras.layers.Dense(nodes_n,activation=activation2))\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def model_search_old(activation,lr,nodes,input_dim,output_dim):\n",
    "    best_R = 0.0\n",
    "    best_lr = 0.0\n",
    "    best_activation = ['none','none','none']\n",
    "    best_nodes = ['none']\n",
    "    for lr_n in lr:\n",
    "        for activation1 in activation:\n",
    "            for acttivation2 in activation:\n",
    "                for activation3 in activation:\n",
    "                    for nodes_n in nodes:\n",
    "                        model = keras.Sequential()\n",
    "                        model.add(keras.layers.Dense(10,input_dim=input_dim,activation=activation2)\n",
    "                        model.add(keras.layers.Dense(nodes_n,activation=activation2))\n",
    "                        model.add(keras.layers.Dense(output_dim,activation=activation3))\n",
    "                \n",
    "                        model.compile(loss='mean_squared_error', optimizer=Adam(lr=lr_n), metrics=[coeff_determination])\n",
    "                        history = model.fit(X_train,Y_train,epochs=15, batch_size=10,validation_split=0.33)\n",
    "                        \n",
    "                        scores = model.evaulate(X_test,Y_test)\n",
    "                        print(scores)\n",
    "                        if scores[1]>0.985:\n",
    "                            best_activation = [activation1,activation2,activation3]\n",
    "                            best_R = scores[1]\n",
    "                            best_nodes = nodes_n\n",
    "                            best_lr = lr_n\n",
    "                            break\n",
    "                        elif scores[1]>best_R:\n",
    "                            best_activation = [activation1,activation2,activation3]\n",
    "                            best_R = scores[1]\n",
    "                            best_nodes = nodes_n\n",
    "                            best_lr = lr_n\n",
    "                        else:\n",
    "                            pass\n",
    "    print (best_R, best_activation,best_nodes,best_lr)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_search(X_train,Y_train,X_test,Y_test\n",
    "    input_dim,output_dim,layers,activation_functions=['tanh','softmax','linear']):\n",
    "    iterations = len(activation_functions)**(layers + 2)\n",
    "    inner_iterations = len(activation_functions)**layers\n",
    "    af_combs = make_pairwise_list(max_depth=layers, options=activation_functions)\n",
    "    print(f'{layers}\\t{activation_functions}\\t{iterations} iterations required')\n",
    "    best_R = 0.0\n",
    "    best_activation = []\n",
    "    iteration_n = 1\n",
    "    for n in range(layers):\n",
    "        best_activation.append('none')\n",
    "    best_activation = []\n",
    "    for inner_iteration in range(inner_iterations):\n",
    "        for activation_in in activation_functions:\n",
    "            for layer in range(layers):\n",
    "                inner_list = []\n",
    "                inner_list.append(af_combs[inner_iteration][layer])\n",
    "                for activation_out in activation_functions:\n",
    "                    print(f\"running iteration {iteration_n}\")\n",
    "                    parameter_list = []\n",
    "                    parameter_list.append(activation_in)\n",
    "                    parameter_list.extend(inner_list)\n",
    "                    parameter_list.append(activation_out)\n",
    "                    print(f\"create input layer with activation of {activation_in}\")\n",
    "                    \n",
    "                    model = keras.Sequential()\n",
    "                    model.add(keras.layers.Dense(10,input_dim = input_dim,activation=activation_in))\n",
    "                    for i in range(len(inner_list)):\n",
    "                        print(f\"create hidden layer {layer} of type {inner_list[i]}\")\n",
    "                        model.add(keras.layers.Dense(20,activation = inner_list[i]))\n",
    "                    print(f\"create output layer with activation of {activation_out}\")\n",
    "                    model.add(keras.layers.Dense(output_dim,activation=activation_out))\n",
    "                    model.compile(loss='mean_squared_error', optimizer='adam', \n",
    "                                  metrics=[coeff_determination])\n",
    "                    history = model.fit(X_train,Y_train,epochs=50, batch_size=10,validation_split=0.33)\n",
    "                    scores = model.evaluate(X_test,Y_test)\n",
    "                    print(scores[1])\n",
    "                    iteration_n += iteration_n \n",
    "                    if scores[1]>best_R:\n",
    "                        best_activation = parameter_list\n",
    "                        best_score = scores[1]\n",
    "                    else:\n",
    "                        pass\n",
    "        print(\"\")\n",
    "    print(best_activation)\n",
    "    print(best_R)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_search(X_train=X_new,Y_train=Y_new,X_test=X_test,Y_test=Y_test,\n",
    "             input_dim=3,output_dim=1,layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_hyperparam_search(layers, activation_functions=['tanh', 'softmax', 'relu']):\n",
    "    iterations = len(activation_functions)**layers\n",
    "    \n",
    "    af_combs = make_pairwise_list(max_depth=layers, options=activation_functions)\n",
    "    \n",
    "    print(f'{layers}\\t{activation_functions}\\t{iterations} iterations required')\n",
    "    for iteration in range(iterations):\n",
    "        print(f\"running interation {iteration}\")\n",
    "        print(\"create input layer\")\n",
    "        for layer in range(layers):\n",
    "            print(f\"create hidden layer {layer} of type {af_combs[iteration][layer]}\")\n",
    "        print(\"create output layer\")\n",
    "        print(\"\")\n",
    "\n",
    "def layer_search(hidden_layers=[1,3,5], \n",
    "                 activation_functions=None):\n",
    "    for layer_count in hidden_layers:\n",
    "        if not activation_functions:\n",
    "            model_hyperparam_search(layer_count)\n",
    "        else:\n",
    "            model_hyperparam_search(layer_count, activation_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model__multi_search(X_train,Y_train,X_test,Y_test,input_dim,output_dim,layers,\n",
    "                        activation_functions=['tanh', 'softmax', 'relu'],Dropout=[0.1,0.5,0.8]):\n",
    "    iterations = (len(Dropout)*len(activation_functions))**(layers+2)\n",
    "    inner_iterations = (len(Dropout)*len(activation_functions))**layers\n",
    "    options= make_combo(option1=activation_functions,option2=Dropout)\n",
    "    af_combs = make_pairwise_list(max_depth=layers, options=options)\n",
    "    print(f'{layers}\\t{activation_functions}\\t{iterations} iterations required')\n",
    "    best_R = 0.0\n",
    "    best_param = []\n",
    "    iteration_n = 1\n",
    "    for n in range(layers):\n",
    "        best_activation.append('none')\n",
    "    best_activation = []\n",
    "    for inner_iteration in range(inner_iterations):\n",
    "        for option_in in options:\n",
    "            for layer in range(layers):\n",
    "                inner_list = []\n",
    "                inner_list.append(af_combs[inner_iteration])\n",
    "                for option_out in options:\n",
    "                    print(f\"running iteration {iteration_n}\")\n",
    "                    parameter_list1 = []\n",
    "                    parameter_list.append(option_in)\n",
    "                    parameter_list.extend(inner_list)\n",
    "                    parameter_list.append(option_out)\n",
    "                    print(f\"create input layer with activation of {option_in[0]} and Dropout of {option_in[1]}\")\n",
    "                    \n",
    "                    model = keras.Sequential()\n",
    "                    model.add(keras.layers.Dense(10,input_dim = input_dim,activation=option_in[0],\n",
    "                               Dropout = option_in[1]                 ))\n",
    "                    for i in range(len(inner_list)):\n",
    "                        print(f\"create hidden layer {layer} of activation {inner_list[i][0]} and Dropout {inner_list[i][1]}\")\n",
    "                        model.add(keras.layers.Dense(20,activation = inner_list[i][0],Dropout = inner_list[i][1]))\n",
    "                    print(f\"create output layer with activation of {option_out[0]} and Dropout of {option_out[1]}\")\n",
    "                    model.add(keras.layers.Dense(output_dim,activation=option_out[0],Dropout=option_out[1]))\n",
    "                    model.compile(loss='mean_squared_error', optimizer='adam', \n",
    "                                  metrics=[coeff_determination])\n",
    "                    history = model.fit(X_train,Y_train,epochs=50, batch_size=10,validation_split=0.33)\n",
    "                    scores = model.evaluate(X_test,Y_test)\n",
    "                    \n",
    "                    iteration_n += iteration_n \n",
    "                    if scores[1]>best_R:\n",
    "                        best_param = parameter_list\n",
    "                        best_score = scores[1]\n",
    "                    else:\n",
    "                        pass\n",
    "        print(\"\")\n",
    "    print(best_param)\n",
    "    print(best_R)\n",
    "    return best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairwise_list(max_depth=2, options=['tanh', 'softmax', 'relu']):\n",
    "    combinations = []\n",
    "    for i in range(len(options)**max_depth):\n",
    "        state = []\n",
    "        for depth in range(max_depth):\n",
    "            if depth == 0:\n",
    "                #print(f\"{i:4}:  {options[i // len(options)**(max_depth-1)]}\", end='  ')\n",
    "                state.append(options[i // len(options)**(max_depth-1)])\n",
    "            elif depth == max_depth - 1:\n",
    "                #print(f\"{options[i % len(options)]}\", end='  ')\n",
    "                state.append(options[i % len(options)])\n",
    "            else:\n",
    "                #print(f\"{options[i // len(options)**(depth) % len(options)]}\", end='  ')\n",
    "                state.append(options[i // len(options)**(depth) % len(options)])\n",
    "        #print(\"\")\n",
    "        combinations.append(state)\n",
    "    return combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not Run Yet\n",
    "def Layer_Number_Decider(Number_Choice,input_dim,opt_activation,X,Y):\n",
    "    Best_score = 0.0\n",
    "    Best_L_Num = 1\n",
    "    for choice_n in Number_Choice:\n",
    "        i = 1\n",
    "        model = Sequntial()\n",
    "        while i <= choice n:\n",
    "            model.add(keras.layers.Dense(5,input_dim=input_dim,activation=opt_activation))\n",
    "        model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['accuracy'])\n",
    "        # Above step will be modified based on other functions to be completed\n",
    "        model.fit(X,Y,epochs=150, batch_size=10,verbose=0)\n",
    "        \n",
    "        scores = model.evaluate(X,Y)\n",
    "        if scores[1] > best_score:\n",
    "            best_score = scores[1]\n",
    "            best_L_Num = choice_n\n",
    "                else:\n",
    "                    pass\n",
    "    \n",
    "    print(best_score, L_num)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following function is Hand_written grid_Search Function\n",
    "# Cross_validation is not included for runtime concerns\n",
    "# This function has worked in other notebook.\n",
    "def Grid_Search(param,X,Y):\n",
    "    import keras\n",
    "    best_score = 0.0\n",
    "    best_activation = ['none','none','none']\n",
    "    # This will be modified so that not only activation could be tuned\n",
    "    # Also number of layers would be more flexible \n",
    "    for param1 in param:\n",
    "        for param2 in param:\n",
    "                model = keras.Sequential()\n",
    "                model.add(keras.layers.Dense(20,input_dim=3,activation=param1))\n",
    "                model.add(keras.layers.Dense(1,activation=param2))\n",
    "                \n",
    "                \n",
    "                model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['accuracy'])\n",
    "                model.fit(X,Y,epochs=150, batch_size=10,verbose=0)\n",
    "                \n",
    "                scores = model.evaluate(X,Y)\n",
    "                if scores[1] > best_score:\n",
    "                    best_score = scores[1]\n",
    "                    best_activation = [param1,param2]\n",
    "                else:\n",
    "                    pass\n",
    "    \n",
    "    print(best_score, best_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script is copied and modified from web\n",
    "# Take too long...\n",
    "# Could be tried later with cluster or super computer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras import Sequential\n",
    "import keras\n",
    "def create_model(activation='relu'):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(keras.layers.Dense(20, input_dim=3,activation=activation))\n",
    "\tmodel.add(keras.layers.Dense(1, activation='linear'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='sgd', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# create model\n",
    "model = KerasRegressor(build_fn=create_model, epochs=150, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "activation = ['tanh','linear','relu']\n",
    "param_grid = dict(activation=activation)\n",
    "# This param_grid could be a any other paramters:initializer, nodes_number,learning_rate\n",
    "# learning momentum, drop_out rate,epoch, batch_size,weight_constraint,etc\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "grid_result = grid.fit(X, Y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd\n",
    "df2 = pd.read_excel('parameter_choice.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('parameter_choice.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>layer number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>layer type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>different layer combination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nodes number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>activation function</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kernel initializer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bias initializer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kernel regularizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bias regularizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kernel constraint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>biase constraint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dropout rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>loss function</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>metric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>optimizer and learning rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>batch_size</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Parameters\n",
       "0                  layer number\n",
       "1                   layer type \n",
       "2   different layer combination\n",
       "3                  nodes number\n",
       "4           activation function\n",
       "5            kernel initializer\n",
       "6              bias initializer\n",
       "7            kernel regularizer\n",
       "8              bias regularizer\n",
       "9             kernel constraint\n",
       "10             biase constraint\n",
       "11                 Dropout rate\n",
       "12                loss function\n",
       "13                       metric\n",
       "14  optimizer and learning rate\n",
       "15                       epochs\n",
       "16                   batch_size"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This to do next:\n",
    "* Find a way to make every function work: shrinking pre_trained sample size, split parameter \n",
    "  and do them one by one, Forward_stepwise selection...?\n",
    "* Data preprossing and standardizing function\n",
    "* Model restoring function\n",
    "* Plot Draw~\n",
    "* .Py Script \n",
    "* Other kinds of neural network and layers\n",
    "* Probably some sel_designing parameter/functions such as weight initilizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
